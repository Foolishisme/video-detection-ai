# **é¡¹ç›®é‡æ„æŒ‡å—ï¼šç«¯äº‘ååŒæ™ºèƒ½è§†è§‰ç³»ç»Ÿ**

# **Edge-Cloud Collaborative Vision System Refactoring Guide**

## **1\. é¡¹ç›®èƒŒæ™¯ä¸ç›®æ ‡**

å½“å‰é¡¹ç›®åŸºäºä¼ ç»Ÿçš„ YOLOv8 \+ å¤æ‚çš„ OpenCV è§„åˆ™ï¼ˆè½¨è¿¹åˆ†æã€å…‰æµæ³•ï¼‰è¿›è¡Œå±é™©åŠ¨ä½œæ£€æµ‹ï¼Œå­˜åœ¨è¯¯æŠ¥ç‡é«˜ã€ä»£ç ç»´æŠ¤å›°éš¾ã€ç®—åŠ›åˆ†é…ä¸åˆç†çš„é—®é¢˜ã€‚  
æœ¬æ¬¡é‡æ„çš„ç›®æ ‡æ˜¯è½¬å‹ä¸º "ç«¯äº‘ååŒ (Edge-Cloud)" æ¶æ„ï¼š

* **Edge (æœ¬åœ°)**: è´Ÿè´£å®æ—¶è§†é¢‘æµé‡‡é›†ã€è½»é‡çº§ç›®æ ‡åˆç­›ï¼ˆåªçœ‹æœ‰æ²¡æœ‰äººï¼‰ã€å…³é”®å¸§å‹ç¼©ä¸ä¸Šä¼ ã€‚  
* **Cloud (è¿œç«¯)**: è´Ÿè´£æ¥æ”¶å›¾åƒï¼Œè¿è¡Œå¤šæ¨¡æ€å¤§æ¨¡å‹ (Qwen2-VL)ï¼Œè¿›è¡Œè¯­ä¹‰çº§çš„å±é™©åˆ¤å®šã€‚

## **2\. æ ¸å¿ƒæ¶æ„è®¾è®¡ (Architecture)**

### **2.1 è§£å†³æ ¸å¿ƒç—›ç‚¹ï¼šæ—¶å»¶ä¸å¸¦å®½**

ä¸ºè§£å†³å¤§æ¨¡å‹å¼•å…¥åçš„æ¨ç†æ—¶å»¶ï¼ˆ\~1.5sï¼‰å’Œå¸¦å®½å ç”¨é—®é¢˜ï¼Œå¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹è®¾è®¡æ¨¡å¼ï¼š

1. **å¼‚æ­¥éé˜»å¡ (Async Non-blocking)**: è§†é¢‘æµé‡‡é›†ä¸æ˜¾ç¤ºï¼ˆMain Threadï¼‰å¿…é¡»ä¸ç½‘ç»œè¯·æ±‚ï¼ˆWorker Threadï¼‰å®Œå…¨åˆ†ç¦»ã€‚ç½‘ç»œå¡é¡¿ç»ä¸èƒ½å¯¼è‡´è§†é¢‘ç”»é¢å¡é¡¿ã€‚  
2. **äº‹ä»¶é©±åŠ¨ (Event Driven)**: ä»…å½“æœ¬åœ° YOLO æ£€æµ‹åˆ° "Person" ä¸”æ»¡è¶³å†·å´æ—¶é—´ï¼ˆCooldownï¼‰æ—¶ï¼Œæ‰è§¦å‘ä¸Šä¼ ã€‚  
3. **æ•°æ®å‹ç¼© (Compression)**: ä¸Šä¼ å‰å°†å›¾åƒ Resize è‡³ 640x640 å¹¶è¿›è¡Œ JPEG å‹ç¼©ï¼ˆQuality=80ï¼‰ï¼Œå°† Payload æ§åˆ¶åœ¨ 50KB ä»¥å†…ã€‚

### **2.2 æ¨¡å—èŒè´£åˆ’åˆ†**

| æ¨¡å— | æ–‡ä»¶å (å»ºè®®) | èŒè´£ | å…³é”®æŠ€æœ¯æ ˆ |
| :---- | :---- | :---- | :---- |
| **äº‘ç«¯æœåŠ¡** | server\_api.py | åŠ è½½ Qwen2-VL æ¨¡å‹ï¼›æä¾› HTTP æ¥å£ï¼›è¿”å› JSON ç»“æœã€‚ | FastAPI, Transformers, Torch |
| **æœ¬åœ°å®¢æˆ·ç«¯** | smart\_monitor.py | è§†é¢‘é‡‡é›†ï¼›YOLOåˆç­›ï¼›**å¼‚æ­¥çº¿ç¨‹æ± **å‘é€è¯·æ±‚ï¼›æŠ¥è­¦é€»è¾‘ã€‚ | OpenCV, YOLOv8, Threading, Requests |
| **é€šç”¨é…ç½®** | config.py | å­˜å‚¨æœåŠ¡å™¨ IPã€ç«¯å£ã€é˜ˆå€¼ã€å†·å´æ—¶é—´ç­‰å‚æ•°ã€‚ | Python Dataclass |

## **3\. åºŸå¼ƒä¸ä¿ç•™ç­–ç•¥ (Refactoring Strategy)**

### **ğŸ”´ åºŸå¼ƒ (Discard / Ignore)**

Cursor åœ¨é‡å†™æ—¶ï¼Œåº”**å®Œå…¨å¿½ç•¥**ä»¥ä¸‹æ—§æ¨¡å—ï¼Œä¸è¦è¯•å›¾ä¿®å¤å®ƒä»¬ï¼š

* src/models/trajectory/\* (è½¨è¿¹åˆ†æ)  
* src/models/motion/\* (å…‰æµã€è¿åŠ¨å†å²)  
* src/models/behavior/\* (ç¡¬ç¼–ç çš„è¡Œä¸ºè§„åˆ™)  
* all\_in\_one\_system.py (æ—§çš„å…¥å£æ–‡ä»¶)

### **ğŸŸ¢ ä¿ç•™ (Keep / Reuse)**

* src/models/video/video\_capture.py: æ‘„åƒå¤´çš„è¿æ¥ä¸é‡è¿é€»è¾‘ï¼ˆå¦‚æœå¥å£®çš„è¯ï¼‰ã€‚  
* yolov8n.pt: æ¨¡å‹æƒé‡æ–‡ä»¶ã€‚  
* src/models/alert/\*: é‚®ä»¶/æ—¥å¿—æŠ¥è­¦çš„åŸºç¡€åŠŸèƒ½ï¼ˆé€»è¾‘éœ€ç®€åŒ–ï¼‰ã€‚

## **4\. æ ¸å¿ƒä»£ç é€»è¾‘è§„èŒƒ (Implementation Specs)**

### **4.1 äº‘ç«¯æ¥å£è§„èŒƒ (Server)**

* **è¾“å…¥**: JSON {"image\_base64": "...", "prompt": "..."}  
* **æ¨¡å‹**: Qwen2-VL-7B-Instruct (éœ€å¤„ç†ä¸º API æœåŠ¡)  
* **è¾“å‡º**: JSON {"is\_danger": bool, "type": str, "description": str}  
* **System Prompt**: å¼ºåˆ¶æ¨¡å‹å……å½“å®‰é˜²ä¸“å®¶ï¼Œè¾“å‡ºä¸¥æ ¼çš„ JSON æ ¼å¼ï¼Œä¸è¦è¾“å‡ºåºŸè¯ã€‚

### **4.2 æœ¬åœ°å®¢æˆ·ç«¯é€»è¾‘æµ (Client)**

åˆå§‹åŒ–:  
  \- åŠ è½½ YOLO æ¨¡å‹  
  \- å¯åŠ¨æ‘„åƒå¤´  
  \- å¯åŠ¨ NetworkWorker çº¿ç¨‹ (Queue)

ä¸»å¾ªç¯ (While True):  
  1\. è¯»å–å¸§ frame  
  2\. YOLO æ¨ç† \-\> è·å¾— results  
  3\. ç»˜å›¾ (ç”»æ¡†)  
  4\. é€»è¾‘åˆ¤æ–­:  
     IF (æœ‰äººåœ¨ç”»é¢ä¸­) AND (å½“å‰æ—¶é—´ \- ä¸Šæ¬¡æŠ¥è­¦æ—¶é—´ \> COOLDOWN):  
         \- æ·±åº¦æ‹·è´å¸§ (frame.copy())  
         \- æ”¾å…¥ NetworkWorker é˜Ÿåˆ—  
         \- æ›´æ–° "æ­£åœ¨åˆ†æ..." çŠ¶æ€ UI  
  5\. æ˜¾ç¤ºå¸§ (cv2.imshow)  
  6\. æ£€æŸ¥ NetworkWorker è¿”å›çš„ç»“æœ \-\> å¦‚æœæ˜¯ Danger \-\> è§¦å‘æŠ¥è­¦

NetworkWorker çº¿ç¨‹:  
  While True:  
     \- ä»é˜Ÿåˆ—è·å– frame  
     \- Resize (640x640) \-\> JPEG å‹ç¼© \-\> Base64  
     \- POST è¯·æ±‚æœåŠ¡å™¨  
     \- è§£æ JSON  
     \- å›è°ƒ/æ›´æ–°å…¨å±€çŠ¶æ€

## **5\. Cursor æç¤ºè¯æŒ‡ä»¤ (Prompts for Cursor)**

è¯·æŒ‰ç…§ä»¥ä¸‹é¡ºåºç”Ÿæˆä»£ç ã€‚

### **æ­¥éª¤ 1: ç”ŸæˆæœåŠ¡ç«¯ä»£ç **

User Query:  
"Create a server\_api.py using FastAPI. It should load the Qwen/Qwen2-VL-7B-Instruct model using Transformers. Create a POST endpoint /v1/vision/analyze that accepts a Base64 image. The model should classify the image for dangerous activities (falling, fighting, fire) and return a strictly formatted JSON response. Use 4-bit quantization if possible to save memory."

### **æ­¥éª¤ 2: ç”Ÿæˆå®¢æˆ·ç«¯ä»£ç **

User Query:  
"Create a smart\_monitor.py for the local edge device.

1. Use cv2 to capture video and ultralytics to load yolov8n.pt.  
2. Implement a **threaded architecture**: The main loop handles video rendering and YOLO detection. A separate daemon thread handles HTTP requests to the server to prevent video freezing.  
3. Only send the image to the server if a 'person' class is detected by YOLO and a 5-second cooldown has passed.  
4. Compress the image (resize to 640px, jpeg quality 80\) before sending to reduce latency.  
5. Display the server's analysis result as an overlay text on the video window."